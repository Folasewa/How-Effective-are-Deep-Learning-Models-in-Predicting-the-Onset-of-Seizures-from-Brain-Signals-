{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca1475e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "import pyedflib\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, filtfilt, iirnotch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8169dd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing patient data: 100%|██████████| 8/8 [00:00<00:00, 3120.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping chb03 (all sessions converted)\n",
      "Skipping chb04 (all sessions converted)\n",
      "Skipping chb05 (all sessions converted)\n",
      "Skipping chb02 (all sessions converted)\n",
      "Skipping chb07 (all sessions converted)\n",
      "Skipping chb01 (all sessions converted)\n",
      "Skipping chb06 (all sessions converted)\n",
      "Yehhh!! Conversion Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"/Users/folasewaabdulsalam/Seizure_Onset/Dataset\"\n",
    "output_dir = \"/Users/folasewaabdulsalam/Seizure_Onset/h5_files\"\n",
    "\n",
    "def convert_edf_to_h5(source_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Convert .edf files to .h5 format\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for patient_folder in tqdm(os.listdir(source_dir), desc=\"Processing patient data\"):\n",
    "        patient_path = os.path.join(source_dir, patient_folder)\n",
    "\n",
    "        if not os.path.isdir(patient_path):\n",
    "            continue\n",
    "\n",
    "        patient_output_dir = os.path.join(output_dir, patient_folder)\n",
    "        os.makedirs(patient_output_dir, exist_ok=True)\n",
    "\n",
    "        edf_files  = [f for f in os.listdir(patient_path) if f.endswith(\".edf\")]\n",
    "        h5_files = [f.replace(\".edf\", \".h5\") for f in edf_files]\n",
    "        already_processed = all(os.path.exists(os.path.join(patient_output_dir, h5_file)) for h5_file in h5_files)\n",
    "\n",
    "        if already_processed:\n",
    "            print(f\"Skipping {patient_folder} (all sessions converted)\")\n",
    "            continue\n",
    "\n",
    "        for edf_file, h5_file in zip(edf_files, h5_files):\n",
    "            edf_path = os.path.join(patient_path, edf_file)\n",
    "            h5_file_path = os.path.join(patient_output_dir, h5_file)\n",
    "\n",
    "            if os.path.exists(h5_file_path):\n",
    "                print(f\"Skipping {edf_file} already converted\")\n",
    "                continue\n",
    "\n",
    "            #extracting raw signals and metadata\n",
    "            with pyedflib.EdfReader(edf_path) as f:\n",
    "                signals = np.array([f.readSignal(i) for i in range(f.signals_in_file)])\n",
    "                channels = f.getSignalLabels()\n",
    "                sampling_rate = f.getSampleFrequency(0)\n",
    "            \n",
    "            with h5py.File(h5_file_path, \"w\") as h5_file:\n",
    "                h5_file.create_dataset(\"data\", data=signals, compression=\"gzip\")\n",
    "                h5_file.attrs[\"channels\"] = channels\n",
    "                h5_file.attrs[\"sampling_rate\"] = sampling_rate\n",
    "\n",
    "                seizure_file = edf_path + \".seizures\"\n",
    "                if os.path.exists(seizure_file):\n",
    "                    with open(seizure_file, \"r\", encoding=\"ISO-8859-1\", errors=\"ignore\") as sf:\n",
    "                        annotations = [line.replace(\"\\x00\", \"\").strip() for line in sf.readlines()]\n",
    "                    h5_file.attrs[\"seizure_annotations\"] = annotations\n",
    "\n",
    "            print(f\"Converted: {edf_file}\")\n",
    "    print(\"Yehhh!! Conversion Complete\")\n",
    "\n",
    "\n",
    "convert_edf_to_h5(source_dir, output_dir)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c69ad90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebac18d",
   "metadata": {},
   "source": [
    "Data Preprocessing Steps\n",
    "Bandpass Filtering (0.5-25Hz)\n",
    "Notch Filtering (50 - 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e42cdc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing .h5 Files: 100%|██████████| 21/21 [11:26<00:00, 32.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/Users/folasewaabdulsalam/Seizure_Onset/h5_all_files\"\n",
    "output_path = \"/Users/folasewaabdulsalam/Seizure_Onset/preprocessed_data\"\n",
    "sampling_rate = 256\n",
    "\n",
    "def bandpass_filter(data, low_cut, high_cut, fs, order=4):\n",
    "    \"\"\"\n",
    "    Apply a Butterworth bandpass filter.\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_data (ndarray): The bandpass filtered data.\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    low = low_cut / nyquist\n",
    "    high = high_cut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return filtfilt(b, a, data, axis=1)\n",
    "\n",
    "def notch_filter(data, notch_freq, fs, quality=30):\n",
    "    \"\"\"\n",
    "    Apply a notch filter to remove powerline interference.\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_data (ndarray): The notch filtered data.\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    b, a = iirnotch(notch_freq / nyquist, quality)\n",
    "    return filtfilt(b, a, data, axis=1)\n",
    "\n",
    "def preprocess_h5_files(data_path, output_path, low_cut=0.5, high_cut=50.0, notch_freq=50.0, fs=256, batch_size=10):\n",
    "    \"\"\"\n",
    "    Preprocess .h5 files by applying bandpass and notch filters.\n",
    "\n",
    "    \"\"\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Get all .h5 files in the directory\n",
    "    h5_files = [f for f in os.listdir(data_path) if f.endswith(\".h5\")]\n",
    "    \n",
    "    for i in tqdm(range(0, len(h5_files), batch_size), desc=\"Preprocessing .h5 Files\"):\n",
    "        batch_files = h5_files[i:i+batch_size]\n",
    "        \n",
    "        for h5_file in batch_files:\n",
    "            file_path = os.path.join(data_path, h5_file)\n",
    "            output_file_path = os.path.join(output_path, h5_file.replace(\".h5\", \"_preprocessed.npy\"))\n",
    "            \n",
    "            with h5py.File(file_path, \"r\") as f:\n",
    "                # Extract signals\n",
    "                signals = f[\"data\"][:]\n",
    "                \n",
    "                # Apply bandpass filter\n",
    "                filtered_signals = bandpass_filter(signals, low_cut, high_cut, fs)\n",
    "                \n",
    "                # Apply notch filter\n",
    "                filtered_signals = notch_filter(filtered_signals, notch_freq, fs)\n",
    "                \n",
    "                # Save the preprocessed data\n",
    "                np.save(output_file_path, filtered_signals)\n",
    "    \n",
    "    print(\"Preprocessing complete!\")\n",
    "\n",
    "# Run the preprocessingp\n",
    "preprocess_h5_files(data_path, output_path, low_cut=0.5, high_cut=50.0, notch_freq=50.0, fs=sampling_rate, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ef063f",
   "metadata": {},
   "source": [
    "8 bank filterbank\n",
    "2-second sliding window\n",
    "feature extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa1a94f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Features: 100%|██████████| 207/207 [00:22<00:00,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessed_path = \"/Users/folasewaabdulsalam/Seizure_Onset/preprocessed_data\"\n",
    "feature_path = \"/Users/folasewaabdulsalam/Seizure_Onset/feature_path\"\n",
    "window_size = 2\n",
    "sampling_rate = 256\n",
    "window_samples = window_size * sampling_rate\n",
    "\n",
    "filter_bands = [\n",
    "    (0.5, 3.625),\n",
    "    (3.625, 6.75),\n",
    "    (6.75, 9.875),\n",
    "    (9.875, 13.0),\n",
    "    (13.0, 16.125),\n",
    "    (16.125, 19.25),\n",
    "    (19.25, 22.375),\n",
    "    (22.375, 25.0)\n",
    "]\n",
    "\n",
    "\n",
    "def extract_spectral_energy(data, fs=256):\n",
    "    \"\"\"\n",
    "    Extracts spectral energy features for each band.\n",
    "\n",
    "    \"\"\"\n",
    "    num_channels = data.shape[0]\n",
    "    features = []\n",
    "\n",
    "    for low_cut, high_cut in filter_bands:\n",
    "        # Calculate the power in each band\n",
    "        band_samples = data[:, int(low_cut * fs):int(high_cut * fs)]\n",
    "        energy = np.sum(band_samples ** 2, axis=1)  # Shape: (channels,)\n",
    "        features.append(energy)\n",
    "\n",
    "    # Flatten to create the final feature vector (8 bands × 18 channels)\n",
    "    return np.concatenate(features)\n",
    "\n",
    "\n",
    "def process_and_save_features(preprocessed_path, feature_path):\n",
    "    \"\"\"\n",
    "    Extract features from all preprocessed files.\n",
    "    \"\"\"\n",
    "    os.makedirs(feature_path, exist_ok=True)\n",
    "\n",
    "    # Get all preprocessed .npy files\n",
    "    npy_files = [f for f in os.listdir(preprocessed_path) if f.endswith(\"_preprocessed.npy\")]\n",
    "    \n",
    "    for npy_file in tqdm(npy_files, desc=\"Processing Features\"):\n",
    "        input_file = os.path.join(preprocessed_path, npy_file)\n",
    "        output_file = os.path.join(feature_path, npy_file.replace(\"_preprocessed.npy\", \"_features.h5\"))\n",
    "        \n",
    "        # Load the preprocessed data\n",
    "        signals = np.load(input_file)  # Shape: (channels, samples)\n",
    "\n",
    "        # Extract features\n",
    "        features = extract_spectral_energy(signals, fs=sampling_rate)\n",
    "\n",
    "        # Save the features in compressed HDF5 format\n",
    "        with h5py.File(output_file, \"w\") as hf:\n",
    "            hf.create_dataset(\"features\", data=features, compression=\"gzip\")\n",
    "        \n",
    "    print(\"Feature extraction complete!\")\n",
    "\n",
    "# Run the filterbank processing\n",
    "process_and_save_features(preprocessed_path, feature_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9a0c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
